{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['original_response', 'last_timestamp', 'cleaned_response',\n",
      "       'human_labelled_response', 'chat_id', 'is_generic', 'prod_names',\n",
      "       '(context,)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#A more concrete example using dataset of finding duplicate questions on quora contest \n",
    "df=pd.read_csv(\"Latest_cleaned_fk.csv\")\n",
    "df.dropna(axis=0,subset=['(context,)','human_labelled_response'],inplace=True)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=list(df[\"(context,)\"])\n",
    "y=list(df[\"human_labelled_response\"])\n",
    "z=list(df[\"chat_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of chats 1003\n"
     ]
    }
   ],
   "source": [
    "z=list(set(z))\n",
    "print(\"No. of chats\",len(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prev=\"\"\n",
    "s=\"\"\n",
    "a=[]\n",
    "chats=[]\n",
    "for i,j,k in zip(x,y,z):\n",
    "    chats.extend(i.split(\" \")+j.split(\" \"))\n",
    "    #print(i,j,k)\n",
    "    if prev==k:\n",
    "        s=s+\" \"+prevj+\" \"+i\n",
    "        a.append(s)\n",
    "        prevj=j\n",
    "    else:\n",
    "        a.append(i)\n",
    "        s=i\n",
    "        prevj=j\n",
    "        prev=k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', 'I', 'am']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "words=Counter(chats)\n",
    "frq_words=words.most_common(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab={}\n",
    "for i,tup in enumerate(frq_words):\n",
    "    vocab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 16249), ('I', 14268), ('to', 12730)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frq_words[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df['context']=a[:len(a)-2000]\n",
    "df['response']=y[:len(y)-2000]\n",
    "df.to_csv(\"trainl_fk.csv\")\n",
    "df=pd.DataFrame()\n",
    "df['context']=a[len(a)-2000:len(a)-1200]\n",
    "df['response']=y[len(y)-2000:len(y)-1200]\n",
    "df.to_csv(\"vall_fk.csv\")\n",
    "df=pd.DataFrame()\n",
    "df['context']=a[len(a)-1200:]\n",
    "df['response']=y[len(y)-1200:]\n",
    "df.to_csv(\"testl_fk.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lens=[len(k.split(\" \")) for k in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in lens:\n",
    "    if i<=20:\n",
    "        count=count+1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N=len(docs) #Total number of documents that are to be ranked\n",
    "avgdl=sum([len(doc) for doc in docs])/len(docs) #average document length\n",
    "#convert words to lower\n",
    "docs=[doc.lower() for doc in docs]\n",
    "queries=[query.lower() for query in queries]\n",
    "def idf(query_word):\n",
    "    nd_qw=sum([1  for doc in docs if query_word in doc]) #Number of documents containing this word\n",
    "    up=N-nd_qw+0.5\n",
    "    down=nd_qw+0.5\n",
    "    #idf=np.log2(up/down)\n",
    "    #print(float(np.log(up/down)))\n",
    "    return float(np.log2(up/down))\n",
    "def tf(query_word,document):\n",
    "    return sum([1 for word in document.split() if word==query_word])\n",
    "#Parameters set to standard values\n",
    "k1=1.2\n",
    "b=0.75 \n",
    "def bm25(query,document):\n",
    "    score_qw=[]\n",
    "    for query_word in query.split():\n",
    "        #print(query_word,idf(query_word),tf(query_word,document))\n",
    "        up=idf(query_word)*tf(query_word,document)*(k1+1)\n",
    "        down=tf(query_word,document)+k1*(0.25+b*(len(document.split())/avgdl))\n",
    "        score_qw.append(up/down)\n",
    "    #print(score_qw)\n",
    "    return sum(score_qw)\n",
    "#This is just for your understanding it wont much help for the contest\n",
    "for query in queries[:2]:\n",
    "    #Only for the top 2 queries\n",
    "    dscore=[]\n",
    "    for doc in docs:\n",
    "        dscore.append(bm25(query,doc))\n",
    "    print(dscore[:10]) #Output restricted to see scores of the first 10 docs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5)\n",
      "[[4, 0, 4, 0, 4, 0, 4, 0, 4, 0], 0.025600863289563108]\n"
     ]
    }
   ],
   "source": [
    "#TEMP\n",
    "from math import log\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "\n",
    "# beam search\n",
    "def beam_search_decoder(data, k):\n",
    "\tsequences = [[list(), 1.0]]\n",
    "\t# walk over each step in sequence\n",
    "\tfor row in data:\n",
    "\t\tall_candidates = list()\n",
    "\t\t# expand each current candidate\n",
    "\t\tfor i in range(len(sequences)):\n",
    "\t\t\tseq, score = sequences[i]\n",
    "\t\t\tfor j in range(len(row)):\n",
    "\t\t\t\tcandidate = [seq + [j], score * -log(row[j])]\n",
    "\t\t\t\tall_candidates.append(candidate)\n",
    "\t\t# order all candidates by score\n",
    "\t\tordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
    "\t\t# select k best\n",
    "\t\tsequences = ordered[:k]\n",
    "\treturn sequences\n",
    "\n",
    "# define a sequence of 10 words over a vocab of 5 words\n",
    "data = [[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "\t\t[0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "\t\t[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "\t\t[0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "\t\t[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "\t\t[0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "\t\t[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "\t\t[0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "\t\t[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "\t\t[0.5, 0.4, 0.3, 0.2, 0.1]]\n",
    "data = array(data)\n",
    "# decode sequence\n",
    "print(data.shape)\n",
    "result = beam_search_decoder(data, 5)\n",
    "# print result\n",
    "for seq in result:\n",
    "\tprint(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
