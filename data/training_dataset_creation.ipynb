{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "#f=open(\"./dialogue_key_value/kvret_train_public.json\")\n",
    "df=pd.read_json(\"kvret_train_public.json\")\n",
    "#df=pd.read_json(\"kvret_test_public.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Knowledgebase cretaion\n",
    "import pandas as pd\n",
    "#f=open(\"./dialogue_key_value/kvret_train_public.json\")\n",
    "#df=pd.read_json(\"./dialogue_key_value/kvret_train_public.json\")\n",
    "colnames=[]\n",
    "for i in range(len(df)):\n",
    "    colnames.append(df[\"scenario\"][i]['kb']['column_names'])\n",
    "#tuples for drive\n",
    "#tuples_d=[('poi','address','val'),('poi','poi_type','val'),('poi','traffic_info','val'),('poi','distance','val')]\n",
    "tuples_d=[('poi','address','val'),('poi','traffic_info','val'),('poi','distance','val')]\n",
    "#tuples for calendar\n",
    "tuples_c=[('event','time','val'),('event','room','val'),('event','party','val'),('event','agenda','val'),('event','date','val')]\n",
    "#tuples for weather\n",
    "tuples_w=[('location','monday','val'),('location','tuesday','val'),('location','wednesday','val'),\n",
    "          ('location','thursday','val'),('location','friday','val'),('location','saturday','val'),\n",
    "          ('location','sunday','val')]\n",
    "kb=[]\n",
    "for i in range(len(df)):\n",
    "    #print(i)\n",
    "    kb_i=[]\n",
    "    if df['scenario'][i]['kb']['items']:\n",
    "        if(df['scenario'][i]['kb']['column_names'][0]==\"poi\"):\n",
    "            for j in range(len(df['scenario'][i]['kb']['items'])):\n",
    "                for k in range(len(tuples_d)):\n",
    "                    tup=[]\n",
    "                    tup.append(df['scenario'][i]['kb']['items'][j][tuples_d[k][0]])\n",
    "                    tup.append(tuples_d[k][1])\n",
    "                    tup.append(df['scenario'][i]['kb']['items'][j][tuples_d[k][1]])\n",
    "                    kb_i.append(tup)\n",
    "            pass\n",
    "        elif(df['scenario'][i]['kb']['column_names'][0]==\"event\"):\n",
    "            for j in range(len(df['scenario'][i]['kb']['items'])):\n",
    "                #tup=[]\n",
    "                for k in range(len(tuples_c)):\n",
    "                    tup=[]\n",
    "                    tup.append(df['scenario'][i]['kb']['items'][j][tuples_c[k][0]])\n",
    "                    tup.append(tuples_c[k][1])\n",
    "                    tup.append(df['scenario'][i]['kb']['items'][j][tuples_c[k][1]])\n",
    "                    kb_i.append(tup)\n",
    "            pass\n",
    "        else:\n",
    "            for j in range(len(df['scenario'][i]['kb']['items'])):\n",
    "                tup=[]\n",
    "                for k in range(len(tuples_w)):\n",
    "                    tup=[]\n",
    "                    tup.append(df['scenario'][i]['kb']['items'][j][tuples_w[k][0]] )\n",
    "                    tup.append(tuples_w[k][1])\n",
    "                    tup.append(df['scenario'][i]['kb']['items'][j][tuples_w[k][1]])\n",
    "                    kb_i.append(tup)\n",
    "            pass\n",
    "    kb.append(kb_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431\n"
     ]
    }
   ],
   "source": [
    "x={'subject':[],'relation':[],'object':[]}\n",
    "for i in kb:\n",
    "    for j in i:\n",
    "        x['subject'].append(j[0])\n",
    "        x['object'].append(j[2])\n",
    "        x['relation'].append(j[1])\n",
    "x=pd.DataFrame(x)\n",
    "x.drop_duplicates(inplace=True)\n",
    "x.to_csv(\"kbtuples.csv\")\n",
    "nkb={}\n",
    "nkb['relation']=x['relation']\n",
    "nkb['subject']=x['subject']\n",
    "nkb['object']=x['subject']+\"_\"+x['relation']\n",
    "nkb=pd.DataFrame(nkb)\n",
    "nkb.drop_duplicates(inplace=True)\n",
    "nkb.to_csv('normalised_kbtuples.csv')\n",
    "print(len(nkb))\n",
    "#Canonical representations\n",
    "objects=[]\n",
    "for kb_i in kb:\n",
    "    for ki in kb_i:\n",
    "        objects.append('_'.join(ki[0].split(\" \"))+'_'+ki[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chats=[]\n",
    "chats_complete=[]\n",
    "for i in range(len(df)):\n",
    "    chat=[]\n",
    "    for j in range(len(df.iloc[i][\"dialogue\"])):\n",
    "        chat.append(str(df.iloc[i][\"dialogue\"][j][\"data\"][\"utterance\"]).strip('\"').lower())\n",
    "        chats_complete.append(str(df.iloc[i][\"dialogue\"][j][\"data\"][\"utterance\"]).strip('\"').lower())\n",
    "    chats.append(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482\n"
     ]
    }
   ],
   "source": [
    "#Preporcessing replacing values with their canonical representations\n",
    "count=0\n",
    "for i,(chat,kb_i) in enumerate(zip(chats,kb)):\n",
    "    for j,ch in enumerate(chat):\n",
    "        for ki in kb_i:\n",
    "            if ki[0].lower() in ch:\n",
    "                poi=ki[0].lower()\n",
    "    for j,ch in enumerate(chat):\n",
    "        #print(ch)\n",
    "        for ki in kb_i:\n",
    "            #print(ki)\n",
    "            if ki[0].lower()==poi:\n",
    "                #print(ki,ch)\n",
    "                #print(\"hello\")\n",
    "                if 'day' in ki[1].lower():\n",
    "                    for kki in ki[1].lower().split(\",\"):\n",
    "                        if kki in ch and ki[2].lower()!='home':\n",
    "                            count=count+1\n",
    "                            chats[i][j]=re.sub(kki,'_'.join(ki[0].split(\" \"))+'_'+ki[1],ch)\n",
    "                if ki[2].lower() in ch and ki[2].lower()!='home':\n",
    "                    count=count+1\n",
    "                    chats[i][j]=re.sub(ki[2].lower(),'_'.join(ki[0].split(\" \"))+'_'+ki[1],ch)\n",
    "    #break\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Making sure to have even number of dialogues in each chat\n",
    "for i in range(len(chats)):\n",
    "    if(len(chats[i])%2!=0):\n",
    "        chats[i]=chats[i][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Without having context i.e not concatenating consecutive dialogue turns\n",
    "inputs=[]\n",
    "outputs=[]\n",
    "for i in range(len(chats)):\n",
    "    #for j in range(len(chats[i])):\n",
    "        inputs.extend(chats[i][::2])\n",
    "        outputs.extend(chats[i][1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809 809\n"
     ]
    }
   ],
   "source": [
    "#FOR ENTIRE CONTEXT\n",
    "inputs=[]\n",
    "outputs=[]\n",
    "for i in range(len(chats)):\n",
    "    sent=''\n",
    "    for j in range(0,len(chats[i]),2):\n",
    "        #print(chats[i][j])\n",
    "        sent+=chats[i][j]+\" \"\n",
    "        inputs.append(sent.strip(\" \"))\n",
    "        outputs.append(chats[i][j+1].strip(\" \"))\n",
    "        sent+=chats[i][j+1]+\" \"\n",
    "print(len(inputs),len(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Trainset creation\n",
    "ndf=pd.DataFrame()\n",
    "ndf[\"inputs\"]=inputs\n",
    "ndf[\"outputs\"]=outputs\n",
    "df1=ndf[:-500]\n",
    "df2=ndf[-500:]\n",
    "df1=pd.concat([df1]*3, ignore_index=True)\n",
    "df2=pd.concat([df2]*3, ignore_index=True)\n",
    "df1=df1.sample(frac=1)\n",
    "df2=df2.sample(frac=1)\n",
    "df1.to_csv(\"train_data.csv\",index=False)\n",
    "df2.to_csv(\"val_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Trainset creation\n",
    "ndf=pd.DataFrame()\n",
    "ndf[\"inputs\"]=inputs\n",
    "ndf[\"outputs\"]=outputs\n",
    "ndf.to_csv(\"test_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "t=Tokenizer()\n",
    "t.fit_on_texts(chats_complete)\n",
    "#t.texts_to_sequences(inputs)\n",
    "vocab=t.word_index\n",
    "objects=list(set(objects))\n",
    "#objects_norm=list(nkb['object'])\n",
    "count=len(vocab)\n",
    "for k,v in vocab.items():\n",
    "    vocab[k]=v-1\n",
    "vocab[\"<pad>\"]=count\n",
    "vocab[\"<unk>\"]=count+1\n",
    "vocab[\"<eos>\"]=count+2\n",
    "count=count+3\n",
    "for obj in objects:\n",
    "    vocab[obj]=count\n",
    "    count=count+1\n",
    "#Dict to json\n",
    "import json\n",
    "with open('vocabulary.json', 'w') as fp:\n",
    "    json.dump(vocab, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
